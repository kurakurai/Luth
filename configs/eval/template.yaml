model:
  model_name: "Qwen/Qwen3-0.6B"
  dtype: "bfloat16"
  gpu_memory_utilization: 0.9
  max_model_length: 32768

model_parameters:
  temperature: 0.0
  max_new_tokens: 16384
  top_k: 50
  top_p: 0.9
  min_p: 0.0

extras:
  enable_thinking: true
  answer_token: "</think>"   # for reasoning tasks we need to specify the answer token like <answer>
  use_chat_template: true
  system_prompt: "Vous Ãªtes un assistant utile."
  num_runs: 1
  output_dir: "results/"
  save_details: true
  push_to_hub: false

tasks:
# French tasks
  - "community|ifeval_fr|0|0"
  - "community|gpqa_diamond_fr|0|0"
  - "community|mmlu_fr|0|0"
  - "community|aime24_fr|0|0"
  - "community|math_500_fr|0|0"

# English tasks
  - "extended|ifeval|0|0"
  - "leaderboard|mmlu|0|0"
  - "lighteval|gpqa:diamond|0|0"
  - "lighteval|math_500|0|0"
  - "lighteval|aime24|0|0"