model:
  model_name: "kurakurai/Luth-LFM2-700M"
  dtype: "bfloat16"
  gpu_memory_utilization: 0.9
  max_model_length: 16384
  # data_parallel_size: 2
  tensor_parallel_size: 4
  # trust_remote_code: true # LFM2-VL
  

model_parameters:
  temperature: 0.0
  max_new_tokens: 8192

extras:
  num_runs: 3 # Number of runs (result will be averaged)
  enable_prefix_caching: false # Set to false for LFM2 models
  enable_thinking: false
  answer_token: "</think>"  
  use_chat_template: true
  system_prompt: "You are a helpful assistant."
  output_dir: "results/"
  save_details: false
  push_to_hub: false 

tasks:
# French tasks
  - "community|ifeval_fr|0|0"
  - "community|gpqa_fr:diamond|0|0"
  - "community|mmlu_fr|0|0"
  - "community|math_500_fr|0|0"
  - "community|hellaswag_fr|0|0"
  - "community|arc_challenge_fr|0|0"

# English tasks
  - "extended|ifeval|0|0"
  - "leaderboard|mmlu|0|0"
  - "community|gpqa:diamond|0|0"
  - "community|math_500|0|0"
  - "leaderboard|hellaswag|0|0"
  - "leaderboard|arc:challenge|0|0"
